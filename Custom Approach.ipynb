{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing Libraries"
      ],
      "metadata": {
        "id": "-lUUOKxLCkcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch --quiet\n"
      ],
      "metadata": {
        "id": "Y49Ww3DKDCnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-forecasting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfOjPZFEDCRe",
        "outputId": "74c3f437-9136-496a-a862-876ceabbac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-forecasting in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.0.2)\n",
            "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.5.2)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.15.3)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.6.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2025.3.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.14.3)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.7.4)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.14.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Baseline U-Net model for segmentation"
      ],
      "metadata": {
        "id": "a1X0srGpw5Lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Drive"
      ],
      "metadata": {
        "id": "tPQ-yL-DBtAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk1TYEs76Ijl",
        "outputId": "b3192a19-b16f-4960-dd9a-00b94f0d9ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/\"\n",
        "orig_dir = os.path.join(base_dir, \"processed_npy\")   # original images & masks\n",
        "aug_dir  = os.path.join(base_dir, \"Hackathonn\")      # augmented images & masks\n"
      ],
      "metadata": {
        "id": "0MHcQUsY-iw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index_to_color = {\n",
        "    0: (0, 255, 255),     # Urban land\n",
        "    1: (255, 255, 0),     # Agriculture land\n",
        "    2: (255, 0, 255),     # Rangeland\n",
        "    3: (0, 255, 0),       # Forest land\n",
        "    4: (0, 0, 255),       # Water\n",
        "    5: (255, 255, 255),   # Barren land\n",
        "    6: (0, 0, 0)          # Unknown\n",
        "}\n",
        "\n",
        "def label_mask_to_rgb(mask):\n",
        "    rgb_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
        "    for idx, color in index_to_color.items():\n",
        "        rgb_mask[mask == idx] = color\n",
        "    return rgb_mask\n"
      ],
      "metadata": {
        "id": "_2piiSFrAdui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_npy_sample(image_path, mask_path):\n",
        "    img = np.load(image_path)\n",
        "    mask = np.load(mask_path)\n",
        "    rgb_mask = label_mask_to_rgb(mask)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    axs[0].imshow(img)\n",
        "    axs[0].set_title(\"Image\")\n",
        "    axs[1].imshow(rgb_mask)\n",
        "    axs[1].set_title(\"Mask\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "hspD1Jo0AgCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Pytorch Dataset"
      ],
      "metadata": {
        "id": "pAb_I3DvCBzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths  = mask_paths\n",
        "        self.transform   = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = np.load(self.image_paths[idx]).astype(np.float32)  # HWC\n",
        "        msk = np.load(self.mask_paths[idx]).astype(np.uint8)     # HW\n",
        "\n",
        "        if self.transform:\n",
        "            img, msk = self.transform(img, msk)\n",
        "\n",
        "        img_tensor = torch.from_numpy(img).permute(2, 0, 1)       # CHW\n",
        "        msk_tensor = torch.from_numpy(msk).long()\n",
        "        return img_tensor, msk_tensor\n"
      ],
      "metadata": {
        "id": "xA2YbWaBAh-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader, ConcatDataset\n",
        "\n",
        "# Original dataset\n",
        "orig_bases = [f.replace(\"_image.npy\", \"\") for f in os.listdir(orig_dir) if f.endswith(\"_image.npy\")]\n",
        "orig_imgs = [os.path.join(orig_dir, f\"{b}_image.npy\") for b in orig_bases]\n",
        "orig_msks = [os.path.join(orig_dir, f\"{b}_mask.npy\")  for b in orig_bases]\n",
        "orig_dataset = SegmentationDataset(orig_imgs, orig_msks)\n",
        "\n",
        "# 85% train / 15% test\n",
        "n_train = int(0.85 * len(orig_dataset))\n",
        "train_orig, test_dataset = random_split(orig_dataset, [n_train, len(orig_dataset)-n_train], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# Augmented dataset\n",
        "aug_bases = [f.replace(\"_image.npy\", \"\") for f in os.listdir(aug_dir) if f.endswith(\"_image.npy\")]\n",
        "aug_imgs = [os.path.join(aug_dir, f\"{b}_image.npy\") for b in aug_bases]\n",
        "aug_msks = [os.path.join(aug_dir, f\"{b}_mask.npy\") for b in aug_bases]\n",
        "aug_dataset = SegmentationDataset(aug_imgs, aug_msks)\n",
        "\n",
        "# Combine\n",
        "train_dataset = ConcatDataset([train_orig, aug_dataset])\n",
        "\n",
        "# Dataloaders\n",
        "batch_size = 1\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "qjzvszeNAjxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Seal Loss"
      ],
      "metadata": {
        "id": "5BY0v9JaCHsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SEALLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, beta=0.3, gamma=0.75, class_frequencies=None, eps=1e-6):\n",
        "        super(SEALLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.eps = eps\n",
        "\n",
        "        if class_frequencies is not None:\n",
        "            class_frequencies = torch.tensor(class_frequencies, dtype=torch.float32)\n",
        "            self.class_weights = 1.0 / (class_frequencies + eps)\n",
        "            self.class_weights = self.class_weights / self.class_weights.sum()\n",
        "        else:\n",
        "            self.class_weights = None\n",
        "\n",
        "    def compute_entropy(self, probs):\n",
        "        log_probs = torch.clamp(probs, min=self.eps).log()\n",
        "        entropy = -torch.sum(probs * log_probs, dim=1, keepdim=True)\n",
        "        entropy = entropy / torch.log(torch.tensor(probs.size(1), dtype=torch.float32))\n",
        "        return entropy\n",
        "\n",
        "    def focal_tversky_loss(self, probs, targets):\n",
        "        TP = (probs * targets).sum(dim=(2, 3))\n",
        "        FP = (probs * (1 - targets)).sum(dim=(2, 3))\n",
        "        FN = ((1 - probs) * targets).sum(dim=(2, 3))\n",
        "        tversky = (TP + self.eps) / (TP + self.alpha * FP + self.beta * FN + self.eps)\n",
        "        return torch.pow(1.0 - tversky, self.gamma)\n",
        "\n",
        "    def class_balanced_iou_loss(self, probs, targets):\n",
        "        intersection = (probs * targets).sum(dim=(2, 3))\n",
        "        union = probs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) - intersection\n",
        "        iou = (intersection + self.eps) / (union + self.eps)\n",
        "        loss = 1.0 - iou\n",
        "        if self.class_weights is not None:\n",
        "            class_weights = self.class_weights.to(loss.device)\n",
        "            loss = loss * class_weights.unsqueeze(0)\n",
        "        return loss\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        if logits.shape != targets.shape:\n",
        "            targets = F.one_hot(targets.long(), num_classes=logits.shape[1])\n",
        "            targets = targets.permute(0, 3, 1, 2).float()\n",
        "\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        entropy = self.compute_entropy(probs).expand_as(probs)\n",
        "        ftl = self.focal_tversky_loss(probs, targets)\n",
        "        cb_iou = self.class_balanced_iou_loss(probs, targets)\n",
        "        entropy_mean = (entropy * targets).sum(dim=(2, 3)) / (targets.sum(dim=(2, 3)) + self.eps)\n",
        "        seal_loss = (1 - entropy_mean) * ftl + entropy_mean * cb_iou\n",
        "        return seal_loss.mean()\n"
      ],
      "metadata": {
        "id": "yhQ-VW3wAlrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Model"
      ],
      "metadata": {
        "id": "QVTrA9ThCLxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ranger21\n",
        "\n",
        "from ranger21 import Ranger21\n",
        "import segmentation_models_pytorch as smp\n",
        "from torchmetrics import JaccardIndex, F1Score\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Load your model\n",
        "model = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=7).to(device)\n",
        "\n",
        "# Your custom SEAL loss\n",
        "class_freqs =[0.1074, 0.5766, 0.0842, 0.1140, 0.0314, 0.0839, 0.0022]\n",
        "loss_fn = SEALLoss(class_frequencies=class_freqs).to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = Ranger21(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,\n",
        "    num_epochs=10,\n",
        "    num_batches_per_epoch=len(train_loader)\n",
        ")\n",
        "\n",
        "# Evaluation Metrics\n",
        "train_iou = JaccardIndex(task=\"multiclass\", num_classes=7, average=\"macro\").to(device)\n",
        "test_iou  = JaccardIndex(task=\"multiclass\", num_classes=7, average=\"macro\").to(device)\n",
        "train_f1  = F1Score(task=\"multiclass\", num_classes=7, average=\"macro\").to(device)\n",
        "test_f1   = F1Score(task=\"multiclass\", num_classes=7, average=\"macro\").to(device)\n",
        "per_class_iou = JaccardIndex(task=\"multiclass\", num_classes=7, average=None).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pipas9A4An78",
        "outputId": "f99b1289-a576-41c7-8ff1-b019a2a3b6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ranger21 in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from ranger21) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ranger21) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from ranger21) (2.6.0+cu124)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ranger21) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->ranger21) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->ranger21) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->ranger21) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->ranger21) (3.0.2)\n",
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranger21 optimizer ready with following settings:\n",
            "\n",
            "Core optimizer = AdamW\n",
            "Learning rate of 0.0001\n",
            "\n",
            "Important - num_epochs of training = ** 10 epochs **\n",
            "please confirm this is correct or warmup and warmdown will be off\n",
            "\n",
            "Warm-up: linear warmup, over 2000 iterations\n",
            "\n",
            "Lookahead active, merging every 5 steps, with blend factor of 0.5\n",
            "Norm Loss active, factor = 0.0001\n",
            "Stable weight decay of 0.0001\n",
            "Gradient Centralization = On\n",
            "\n",
            "Adaptive Gradient Clipping = True\n",
            "\tclipping value of 0.01\n",
            "\tsteps for clipping = 0.001\n",
            "\n",
            "Warm-down: Linear warmdown, starting at 72.0%, iteration 5889 of 8180\n",
            "warm down will decay until 3e-05 lr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Training and Testing Loop"
      ],
      "metadata": {
        "id": "5kF18REtCbQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_iou.reset(); train_f1.reset()\n",
        "\n",
        "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [train]\"):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        logits = model(X)\n",
        "        loss = loss_fn(logits, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * X.size(0)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        train_iou.update(preds, y)\n",
        "        train_f1.update(preds, y)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    mean_iou = train_iou.compute().item()\n",
        "    f1 = train_f1.compute().item()\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_iou.reset(); test_f1.reset()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} [test]\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            logits = model(X)\n",
        "            loss = loss_fn(logits, y)\n",
        "\n",
        "            test_loss += loss.item() * X.size(0)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            test_iou.update(preds, y)\n",
        "            test_f1.update(preds, y)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    val_iou = test_iou.compute().item()\n",
        "    val_f1 = test_f1.compute().item()\n",
        "    class_iou = per_class_iou(preds, y).tolist()\n",
        "\n",
        "    print(f\"\\n[Epoch {epoch+1}]\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train mIoU: {mean_iou:.4f} | Train F1: {f1:.4f}\")\n",
        "    print(f\" Val  Loss: {test_loss:.4f} |  Val  mIoU: {val_iou:.4f} |  Val  F1: {val_f1:.4f}\")\n",
        "    print(f\"Class-wise IoU: {class_iou}\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSH5wWzPApmA",
        "outputId": "3f8e5afd-23ca-4cd8-cfe7-c59044efc5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10 [train]:   0%|          | 0/818 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params size saved\n",
            "total param groups = 1\n",
            "total params in groups = 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [train]: 100%|██████████| 818/818 [23:03<00:00,  1.69s/it]\n",
            "Epoch 1/10 [test]: 100%|██████████| 121/121 [03:06<00:00,  1.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 1]\n",
            "Train Loss: 0.4957 | Train mIoU: 0.0418 | Train F1: 0.0789\n",
            " Val  Loss: 0.4759 |  Val  mIoU: 0.0394 |  Val  F1: 0.0744\n",
            "Class-wise IoU: [0.061410218477249146, 0.017274903133511543, 0.4928533136844635, 0.0, 0.011071565560996532, 0.1333390176296234, 0.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 [train]: 100%|██████████| 818/818 [23:21<00:00,  1.71s/it]\n",
            "Epoch 2/10 [test]: 100%|██████████| 121/121 [03:13<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 2]\n",
            "Train Loss: 0.4739 | Train mIoU: 0.0644 | Train F1: 0.1162\n",
            " Val  Loss: 0.4707 |  Val  mIoU: 0.0839 |  Val  F1: 0.1336\n",
            "Class-wise IoU: [0.06661699712276459, 0.07000448554754257, 0.031013142317533493, 0.0, 0.0030280915088951588, 0.031238151714205742, 7.925939826236572e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [train]:  45%|████▍     | 365/818 [10:20<11:47,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "** Ranger21 update = Warmup complete - lr set to 0.0001\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [train]: 100%|██████████| 818/818 [22:54<00:00,  1.68s/it]\n",
            "Epoch 3/10 [test]: 100%|██████████| 121/121 [03:13<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 3]\n",
            "Train Loss: 0.4738 | Train mIoU: 0.0951 | Train F1: 0.1463\n",
            " Val  Loss: 0.4707 |  Val  mIoU: 0.0931 |  Val  F1: 0.1289\n",
            "Class-wise IoU: [0.0035974711645394564, 0.06241902336478233, 0.14136020839214325, 0.0, 6.405486783478409e-05, 0.0018754435004666448, 0.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 [train]: 100%|██████████| 818/818 [23:12<00:00,  1.70s/it]\n",
            "Epoch 4/10 [test]: 100%|██████████| 121/121 [03:10<00:00,  1.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 4]\n",
            "Train Loss: 0.4737 | Train mIoU: 0.0999 | Train F1: 0.1462\n",
            " Val  Loss: 0.4707 |  Val  mIoU: 0.0964 |  Val  F1: 0.1353\n",
            "Class-wise IoU: [0.01201804168522358, 0.0605168454349041, 0.17320877313613892, 0.0, 4.99875022796914e-06, 0.0002950706402771175, 0.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 [train]: 100%|██████████| 818/818 [22:28<00:00,  1.65s/it]\n",
            "Epoch 5/10 [test]: 100%|██████████| 121/121 [02:56<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 5]\n",
            "Train Loss: 0.4737 | Train mIoU: 0.1037 | Train F1: 0.1520\n",
            " Val  Loss: 0.4707 |  Val  mIoU: 0.0951 |  Val  F1: 0.1375\n",
            "Class-wise IoU: [0.008579639717936516, 0.028851786628365517, 0.42467695474624634, 0.0, 0.00015898558194749057, 0.0001200810875161551, 0.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 [train]: 100%|██████████| 818/818 [22:26<00:00,  1.65s/it]\n",
            "Epoch 6/10 [test]: 100%|██████████| 121/121 [03:04<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 6]\n",
            "Train Loss: 0.4736 | Train mIoU: 0.1113 | Train F1: 0.1650\n",
            " Val  Loss: 0.4707 |  Val  mIoU: 0.1043 |  Val  F1: 0.1536\n",
            "Class-wise IoU: [0.001629198668524623, 0.0674050897359848, 0.5923591256141663, 0.0, 0.001139810192398727, 0.0016238020034506917, 0.00012259033974260092]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 [train]: 100%|██████████| 818/818 [22:57<00:00,  1.68s/it]\n",
            "Epoch 7/10 [test]: 100%|██████████| 121/121 [03:04<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 7]\n",
            "Train Loss: 0.4735 | Train mIoU: 0.1269 | Train F1: 0.1937\n",
            " Val  Loss: 0.4707 |  Val  mIoU: 0.1054 |  Val  F1: 0.1528\n",
            "Class-wise IoU: [0.004218069836497307, 0.012083563953638077, 0.5444685816764832, 0.0, 0.0003346022276673466, 0.006770881358534098, 6.690082227578387e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 [train]:  18%|█▊        | 144/818 [03:57<18:22,  1.64s/it]"
          ]
        }
      ]
    }
  ]
}